# leap-gesture-ml

The purpose of this project is to develop a gesture recognition system using leap motion devices and machine learning, in consultation with artist Lucinda Boermans. The motivation for this is to investigate the potential of such a tool to be used in the exploration of gesture and communication. Currently, this repository stands as a test of feasibility, implementing gesture recognition and the capture of 'affective dimensions' which are displayed live in a simple GUI.

The next step is to extend this to a conversational context, in which this digital interface would be used to facilitate the interaction of two people communicating through gestures and movement based affectation.

The project as it currently stands has two main parts:
1. Training LSTM based models for recognizing gestures using a leap motion capture device;
2. Using such models with a leap motion capture device in a live environment, such that predictions and other 'affective' information can be viewed in real time.

